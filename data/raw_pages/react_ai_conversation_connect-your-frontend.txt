Connect your frontend
In this guide, you will learn how to create, update, and delete conversations, as well as send messages and subscribe to assistant responses.
Conversations and their associated messages are persisted in Amazon DynamoDB. This means the previous messages for a conversation are automatically included in the history sent to the LLM. Access to conversations and messages are scoped to individual users through the
owner based authorization strategy
.
There are two main types within the conversation flow,
Conversation
and
Message
.
A
Conversation
is an instance of a chat session between an application user and an LLM. It contains data and methods for interacting with the conversation. A conversation has a one-to-many relationship with its messages.
The
Conversation
type is accessible via
Schema['myChat']['type']
type definition, where
'myChat'
is the name of the conversation route in your data schema.
A
Message
is a single chat message between an application user and an LLM. Each message has a
role
property that indicates whether the message is from the user or the assistant. User and assistant messages have a one-to-one relationship. Assistant messages contain an
associatedUserMessageId
property that points to the
id
of the user message that triggered the assistant response.
The
Message
type is accessible via
Schema['myChat']['messageType']
, where
'myChat'
is the name of the conversation route in your data schema.
Create a new conversation with
.create()
or get an existing one with
.get()
.
Subscribe to assistant responses for a conversation with
.onStreamEvent()
.
Send messages to the conversation with
.sendMessage()
.
Create a new conversation by calling the
.create()
method on your conversation route. In the examples below, we're using a conversation route named
chat
.
You can optionally attach a
name
and
metadata
to a conversation by passing them as arguments to the
.create()
method. There are no uniqueness constraints on conversation
name
or
metadata
values.
You can get an existing conversation by calling the
.get()
method on your conversation route with the conversation's
id
.
You can list all conversations for a user with the
.list()
method. Retrieved conversations are sorted by
updatedAt
in descending order. This means the most recently used conversations are returned first.
Use the
nextToken
value to paginate through conversations and optionally specify a
limit
to limit the number of conversations returned.
You can update a conversation's
name
and
metadata
with the
.update()
method.
This is useful if you want to update the conversation name based on the messages sent or attach arbitrary metadata at a later time.
Deleting a conversation makes it unusable in the future. However it does not delete its associated messages.
Once you have a conversation instance, you can interact with it by calling methods on the instance. These methods are documented in the
Conversation and Message types
section.
Once you have a conversation instance, you can send a message to the AI assistant by calling the
.sendMessage()
method. In its simplest form you just pass the message content as text.
The message returned is the user message sent. Assistant messages are streamed back to the client and can be subscribed to with the
.onStreamEvent()
method. See
Subscribe to assistant responses
for more information.
There are other arguments you can pass to
.sendMessage()
to customize the message according to your application's needs.
Customizing the message content
sendMessage()
accepts a object type with a
content
property that provides a flexible way to send different types of content to the AI assistant.
Image Content
Use
image
to send an image to the AI assistant.
Supported image formats are
png
,
gif
,
jpeg
, and
webp
.
Mixing
text
and
image
in a single message is supported.
AI context
The
aiContext
argument allows you to optionally attach arbitrary data to the message. This is useful for passing additional information, like user information or current state of your application, in a user message to the AI assistant.
The
toolConfiguration
argument allows you to optionally pass a client tool configuration to the AI assistant with a user message. See the
Tools concept page
and
Tools guide
for more information on how tools works.
Client tools are conceptually the same as data tools and lambda executable tools. They are API definitions provided to an LLM alongside a user message. The LLM can use the provided tool configuration to decide which tool (if any) to call in order to better respond to the user. However, there's an important distinction with client tools -- you are responsible for implementing the tool execution logic and responding to the AI assistant with the tool's response.
The
json
property is simply a JSON Schema definition of the tool's input. The AI assistant will use this schema to provide the expected input to your tool.
The response from the AI assistant will be a JSON object that matches the
inputSchema
definition. See
Subscribe to assistant responses
for more information on how to handle the response.
Assistant responses are streamed back to the client as they are generated. This allows for a more natural conversation flow where the user doesn't have to wait for a complete response from the AI assistant to see progress and begin reading the response. To subscribe to assistant responses, call the
.onStreamEvent()
method on your conversation instance.
onStreamEvent()
takes two callback functions as arguments:
next
and
error
. The
next
callback is invoked with each assistant response.
The
error
callback is invoked if there's an error while processing messages.
The
next
callback is invoked with a
ConversationStreamEvent
object. This type is accessible via
Schema['myChat']['streamEventType']
and is a union of the following types:
ConversationStreamTextEvent
As text is streamed back to the client, the
next
callback is invoked with a
ConversationStreamTextEvent
object.
ConversationStreamDoneAtIndexEvent
When the AI assistant completes a content block, the
next
callback is invoked with a
ConversationStreamDoneAtIndexEvent
object.
ConversationStreamTurnDoneEvent
When the AI assistant completes a turn, the
next
callback is invoked with a
ConversationStreamTurnDoneEvent
object. This event indicates that the assistant has completed a turn and is waiting for the next user message.
When the AI assistant uses a client tool, the
next
callback is invoked with a
ConversationStreamToolUseEvent
object. Tool use events are accumulated in your cloud resources and sent to the client as a single event.
A note on ordering
There are no guarantees that events will be received by the client in order. For example, a
ConversationStreamTextEvent
with
contentBlockDeltaIndex
of
1
may be received before the preceding text with
contentBlockDeltaIndex
of
0
. Assume that events may be received out of order and use the
contentBlockIndex
and
contentBlockDeltaIndex
properties to order the events as needed.
Retrieve all messages for a conversation by calling the
.listMessages()
method on your conversation instance. Recall that messages are automatically persisted, so you can retrieve them at any time to display the conversation history.
Similar to the
client.conversations.chat.list()
method, retrieved messages are paginated. Use the
nextToken
value to paginate through messages and optionally specify a
limit
to limit the number of messages returned.